ROSTemplateFormatVersion: '2015-09-01'

Resources:
  RAMRole:
    Type: ALIYUN::RAM::Role
    Properties:
      RoleName:
        Fn::Replace:
          - <random-suffix>:
              Ref: ALIYUN::StackName
          - ETLDemoRole-<random-suffix>
      Description: 'RAM role for etl demo'
      AssumeRolePolicyDocument:
        Version: 1
        Statement:
          - Action: sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - fc.aliyuncs.com
                - fnf.aliyuncs.com
      Policies:
        - PolicyName:
            Fn::Replace:
              - <random-suffix>:
                  Ref: ALIYUN::StackName
              - ETLDemoRAMPolicy-<random-suffix>
          PolicyDocument:
            Version: 1
            Statement:
              - Effect: Allow
                Action:
                  - fc:InvokeFunction
                  - oss:*
                Resource:
                  - '*'

  # Create OSS Bucket
  OSSBucket:
    Type: ALIYUN::OSS::Bucket
    Properties:
      BucketName:
        Fn::Replace:
        - <random-suffix>:
            Ref: ALIYUN::StackName
        - demo-etl-<random-suffix>
      AccessControl: private

  # Create FC service
  Service:
    DependsOn:
      - RAMRole
      - OSSBucket
    Type: ALIYUN::FC::Service
    Properties:
      ServiceName:
        Fn::Replace:
          - <random-suffix>:
              Ref: ALIYUN::StackName
          - demo-etl-<random-suffix>
      Role:
        Fn::Replace:
          - <main-account-id>:
              Ref: ALIYUN::TenantId
            <random-suffix>:
              Ref: ALIYUN::StackName
          - acs:ram::<main-account-id>:role/ETLDemoRole-<random-suffix>
      InternetAccess: true

  # Create function shards-spliter
  FunctionShardsSpliter:
    Type: ALIYUN::FC::Function
    DependsOn:
      - Service
    Properties:
      ServiceName:
        Fn::Replace:
          - <random-suffix>:
              Ref: ALIYUN::StackName
          - demo-etl-<random-suffix>
      Code:
        SourceCode:
          |-
          # -*- coding: utf-8 -*-
          import json
          import random

          # each shard has 3 pieces of data
          shard_data_count = 3


          def handler(event, context):
            shards = []
            shard_ids = []
            # split data to shards, may get 3-5 pieces of shards
            seed = random.randint(2, 4)
            for shard_num in range(seed):
              shard_name = "shard_%s" % shard_num
              shard_ids.append(shard_name)
              shard_data = {
                "id": shard_name,
                "data": []
              }
              for count in range(shard_data_count):
                data_value = random.randint(1, 2)
                data = "data_%s" % data_value
                shard_data["data"].append(data)
              shards.append(shard_data)
            return json.dumps({'shards': shards, 'shard_ids': shard_ids})

      FunctionName: shards-spliter
      Handler: index.handler
      Runtime: python3
      MemorySize: 128
      Timeout: 60

  # Create function mapper
  FunctionMapper:
    Type: ALIYUN::FC::Function
    DependsOn:
      - Service
    Properties:
      ServiceName:
        Fn::Replace:
          - <random-suffix>:
              Ref: ALIYUN::StackName
          - demo-etl-<random-suffix>
      Code:
        SourceCode:
          Fn::Replace:
            - <random-suffix>:
                Ref: ALIYUN::StackName
              <region>:
                Ref: ALIYUN::Region
            - |-
              # -*- coding: utf-8 -*-
              import json
              import oss2
              from enum import Enum
              oss_endpoint = "oss-<region>-internal.aliyuncs.com"
              oss_bucket = "demo-etl-<random-suffix>"
              intermediate_result_prefix = "map_%s"
              class ErrorCodes(Enum):
                # common error codes
                StatusSuccess = "operation success"
                # for mapping
                OSSPushObjectFailed = "push result to oss failed"
              class ErrorNeedsRetry(Exception):
                pass
              class Mapper:
                """
                Mapping operation class
                """
                def __init__(self, context, shard_id, shard_data):
                  """
                  :param context: fc input context, used for getting credential.
                  :param shard_id: shard id to be dealt
                  :param shard_data: data to be dealt
                  """
                  creds = context.credentials
                  self.mapping_result_file = intermediate_result_prefix % shard_id
                  auth = oss2.StsAuth(creds.access_key_id, creds.access_key_secret, creds.security_token)
                  self.bucket = oss2.Bucket(auth, oss_endpoint, oss_bucket)
                  self.data = shard_data
                  self.mapping_result = {}
                def process(self):
                  """ process data.
                  :return:
                  """
                  for data in self.data:
                    if data in self.mapping_result.keys():
                      self.mapping_result[data] += 1
                    else:
                      self.mapping_result[data] = 1
                  return
                def persist(self):
                  """ touch file in oss. True will be returned if operation succeeded.
                  :return: bool
                  """
                  resp = self.bucket.put_object(self.mapping_result_file, json.dumps(self.mapping_result))
                  return resp.status == 200
              def handler(event, context):
                evt = json.loads(event)
                shard = evt["shard"]
                mapper = Mapper(context, shard["id"], shard["data"])
                # start mapping data processing
                mapper.process()
                # save to oss bucket
                if not mapper.persist():
                  raise ErrorNeedsRetry(ErrorCodes.OSSPushObjectFailed.value)
                return json.dumps({"MappingStatus": ErrorCodes.StatusSuccess.value})
      FunctionName: mapper
      Handler: index.handler
      Runtime: python3
      MemorySize: 128
      Timeout: 60

  # Create function reducer
  FunctionReducer:
    Type: ALIYUN::FC::Function
    DependsOn:
      - Service
    Properties:
      ServiceName:
        Fn::Replace:
          - <random-suffix>:
              Ref: ALIYUN::StackName
          - demo-etl-<random-suffix>
      Code:
        SourceCode:
          Fn::Replace:
            - <random-suffix>:
                Ref: ALIYUN::StackName
              <region>:
                Ref: ALIYUN::Region
            - |-
              # -*- coding: utf-8 -*-
              import json
              import oss2
              from enum import Enum
              from aliyunsdkcore.acs_exception.exceptions import *
              oss_endpoint = "oss-<region>-internal.aliyuncs.com"
              oss_bucket = "demo-etl-<random-suffix>"
              intermediate_result_prefix = "map_%s"
              final_result = "reduced_result"
              class ErrorCodes(Enum):
                # common error codes
                StatusSuccess = "operation success"
                # for reducing
                OSSGetObjectFailed = "get mapping result to oss failed"
                OSSPushObjectFailed = "push result to oss failed"
              class ErrorNeedsRetry(Exception):
                pass
              class Reducer:
                """
                reducing operation class
                """
                def __init__(self, context, shard_ids):
                  """
                  :param context: fc input context, used for getting credential.
                  :param shard_ids: total shards
                  """
                  creds = context.credentials
                  self.shard_ids = shard_ids
                  auth = oss2.StsAuth(creds.access_key_id, creds.access_key_secret, creds.security_token)
                  self.bucket = oss2.Bucket(auth, oss_endpoint, oss_bucket)
                  self.intermediate_result = []
                  self.final_result = {}
                def fetch_mapping_result(self):
                  """
                  :return: bool
                  """
                  for shard_id in self.shard_ids:
                    try:
                      object_stream = self.bucket.get_object(intermediate_result_prefix % shard_id)
                      file_content = object_stream.read()
                      self.intermediate_result.append(json.loads(file_content))
                    except oss2.exceptions.NoSuchKey:
                      return False
                    except json.decoder.JSONDecodeError:
                      # data crash
                      return False
                  return True
                def reducing(self):
                  """
                  :return: None
                  """
                  # use this map to make data calculation process more easily for reading.
                  for data in self.intermediate_result:
                    for data_type in data:
                      if data_type in self.final_result.keys():
                        self.final_result[data_type] += data[data_type]
                      else:
                        self.final_result[data_type] = data[data_type]
                  return
                def persist(self):
                  """ touch file in oss. True will be returned if operation succeeded.
                  :return: bool
                  """
                  resp = self.bucket.put_object(final_result, json.dumps(self.final_result))
                  return resp.status == 200
              def handler(event, context):
                evt = json.loads(event)
                shard_ids = evt["shard_ids"]
                reducer = Reducer(context, shard_ids)
                # receive map result
                if not reducer.fetch_mapping_result():
                  raise ErrorNeedsRetry(ErrorCodes.OSSGetObjectFailed.value)
                # reducing
                reducer.reducing()
                # save to oss bucket
                if not reducer.persist():
                  raise ErrorNeedsRetry(ErrorCodes.OSSPushObjectFailed.value)
                return json.dumps({"ReducingStatus": ErrorCodes.StatusSuccess.value})
      FunctionName: reducer
      Handler: index.handler
      Runtime: python3
      MemorySize: 128
      Timeout: 60

  Flow:
    DependsOn:
      - RAMRole
    Type: ALIYUN::FNF::Flow
    Properties:
      Description: "FnF etl demo"
      Name:
        Fn::Replace:
          - <random-suffix>:
              Ref: ALIYUN::StackName
          - demo-etl-<random-suffix>
      RoleArn:
        Fn::Replace:
          - <main-account-id>:
              Ref: ALIYUN::TenantId
            <random-suffix>:
              Ref: ALIYUN::StackName
          - acs:ram::<main-account-id>:role/ETLDemoRole-<random-suffix>
      Definition:
        Fn::Replace:
          - <random-suffix>:
              Ref: ALIYUN::StackName
          - |-
            version: v1beta1
            type: flow
            steps:
              # 本步骤调用函数计算 fetcher.py，获取划分的 batch 及对应数据
              - type: task
                name: fetcher
                resourceArn: acs:fc:::services/demo-etl-<random-suffix>/functions/shards-spliter
                outputMappings:
                  - target: shards
                    source: $local.shards
                  - target: shard_ids
                    source: $local.shard_ids
                retry:
                  - errors:
                      - ErrorNeedsRetry
                    intervalSeconds: 10
                    maxAttempts: 3
                    multiplier: 2
                  - errors:
                      - FC.ResourceThrottled
                      - FC.ResourceExhausted
                      - FC.InternalServerError
                      - FnF.TaskTimeout
                      - FC.Unknown
                    intervalSeconds: 3
                    maxAttempts: 10
                    multiplier: 2
                catch: # 捕获 fetcher 抛出的 ErrorNeedsRetry 错误，跳转到 retryFailed
                  - errors:
                    - ErrorNeedsRetry
                    goto: retryFailed
              # 本步骤为 Map，根据上一步划分的 shards 数量创建对应实例并行处理
              - type: foreach
                name: mapping
                inputMappings:
                  - target: shards
                    source: $local.shards
                iterationMapping:
                  collection: $.shards
                  item: shard
                steps:
                  - type: task
                    name: singleMappingJob
                    resourceArn: acs:fc:::services/demo-etl-<random-suffix>/functions/mapper
                    retry:
                      - errors:
                          - ErrorNeedsRetry
                        intervalSeconds: 10
                        maxAttempts: 3
                        multiplier: 2
                      - errors:
                          - FC.ResourceThrottled
                          - FC.ResourceExhausted
                          - FC.InternalServerError
                          - FnF.TaskTimeout
                          - FC.Unknown
                        intervalSeconds: 3
                        maxAttempts: 10
                        multiplier: 2
              # 本步骤为 reduce，合并所有 shards 的 Map 结果，并将最终的处理结果存储到数据仓库中
              - type: task
                name: reducing
                resourceArn: acs:fc:::services/demo-etl-<random-suffix>/functions/reducer
                inputMappings:
                  - target: shard_ids
                    source: $local.shard_ids
                retry:
                  - errors:
                      - ErrorNeedsRetry
                    intervalSeconds: 10
                    maxAttempts: 3
                    multiplier: 2
                  - errors:
                      - FC.ResourceThrottled
                      - FC.ResourceExhausted
                      - FC.InternalServerError
                      - FnF.TaskTimeout
                      - FC.Unknown
                    intervalSeconds: 3
                    maxAttempts: 10
                    multiplier: 2
                catch: # 捕获 reducing 抛出的重试多次异常错误，跳转到 retryFailed
                  - errors:
                    - ErrorNeedsRetry
                    goto: retryFailed
                end: true
              - type: fail
                name: retryFailed
                error: StatusFailed
                cause: retry several times failed